{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "cifar10_cnn_tuning_hyporas_v2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxvKic7TrXF1",
        "outputId": "9a5a592a-5c64-421e-b1ec-c6d5cc95bb54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 2.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-2.4.6'\n",
        "spark_version = 'spark-3.0.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install hyperas\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "\n",
        "# from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice,uniform\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connecting to security.u\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to cloud.r-project.o\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Fetched 252 kB in 2s (127 kB/s)\n",
            "Reading package lists... Done\n",
            "Requirement already satisfied: hyperas in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.4.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.0.7)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.6.1)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.18.5)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (7.5.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.10.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.7.7)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.3.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.6.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.3.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.2.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.6.0)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.11.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.6.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (3.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (4.41.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (1.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (1.0.18)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (5.3.5)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (3.5.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (5.1.1)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (19.0.2)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (1.9.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.9.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1->nbformat->hyperas) (4.4.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (20.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas) (0.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->jupyter-console->jupyter->hyperas) (2.8.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (50.3.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->hyperas) (0.6.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->hyperas) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXP0TDbd4LpT"
      },
      "source": [
        "batch_size = 32  # The default batch size of keras.\n",
        "num_classes = 10  # Number of class for the dataset\n",
        "epochs = 50\n",
        "data_augmentation = False"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWvb-FuH2uBu",
        "outputId": "dad9ae67-a83b-4f15-c294-4677aa0d6e3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# The data, split between train and test sets:\n",
        "(X_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM9OTlp05Neq",
        "outputId": "1a13380c-2f04-4526-9af5-6dd42f7ba104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
        "# Count plot for training set\n",
        "sns.countplot(y_train.ravel(), ax=axs[0])\n",
        "axs[0].set_title('Distribution of training data')\n",
        "axs[0].set_xlabel('Classes')\n",
        "# Count plot for testing set\n",
        "sns.countplot(y_test.ravel(), ax=axs[1])\n",
        "axs[1].set_title('Distribution of Testing data')\n",
        "axs[1].set_xlabel('Classes')\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tBiBCA25OrC"
      },
      "source": [
        "# Normalize the data. Before we need to connvert data type to float for computation.\n",
        "X_train = X_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "X_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices. This is called one hot encoding.\n",
        "y_train_cat = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test_cat = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn_Jf4hviZf5",
        "outputId": "9464d1d3-b22b-462c-c4e2-da5345c7c745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqq676_r-Td-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def data():\n",
        "    (X_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    # X_train = X_train.reshape(50000, 3072)\n",
        "    # x_test = x_test.reshape(10000, 3072)\n",
        "    # Normalize the data. Before we need to connvert data type to float for computation.\n",
        "    X_train = X_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    X_train /= 255\n",
        "    x_test /= 255\n",
        "    num_classes = 10\n",
        "\n",
        "    # Convert class vectors to binary class matrices. This is called one hot encoding.\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "    X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, random_state=42, test_size=0.2)\n",
        "    return X_train2, y_train2, X_val, y_val"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-MGOuYy-qT2",
        "outputId": "a388a123-f28d-4a44-c4b6-49625cc5f0b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "X_train2, y_train2, X_val, y_val = data()\n",
        "print('X_train shape:', X_train2.shape)\n",
        "print('y_train shape:', y_train2.shape)\n",
        "print('x_val shape:', X_val.shape)\n",
        "print('y_val shape:', y_val.shape)\n",
        "X_train2.shape[1:]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (40000, 32, 32, 3)\n",
            "y_train shape: (40000, 10)\n",
            "x_val shape: (10000, 32, 32, 3)\n",
            "y_val shape: (10000, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS9Dgo8C5Rxj"
      },
      "source": [
        "def create_model(X_train2, y_train2, X_val, y_val):\n",
        "\n",
        "    num_classes = 10\n",
        "\n",
        "    #define the convnet\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "\n",
        "    model.add(Conv2D({{choice([16, 32, 64])}}, \n",
        "                     kernel_size={{choice([(3, 3),(5,5)])}},\n",
        "                     padding=\"valid\",input_shape=X_train2.shape[1:]))\n",
        "    \n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D({{choice([16, 32, 64])}}, \n",
        "                     kernel_size={{choice([(3, 3),(5,5)])}},\n",
        "                     padding=\"valid\"))\n",
        "    \n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # model.add(MaxPooling2D(pool_size={{choice([(2, 2),(4,4)])}}))\n",
        "\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "\n",
        "    # CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "\n",
        "    model.add(Conv2D({{choice([16, 32, 64])}}, \n",
        "                     kernel_size={{choice([(3, 3),(5,5)])}}, \n",
        "                     padding='valid'))\n",
        "    \n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D({{choice([16, 32, 64])}}, \n",
        "                     kernel_size={{choice([(3, 3),(5,5)])}}))\n",
        "    \n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # model.add(MaxPooling2D(pool_size={{choice([(2, 2),(4,4)])}}))\n",
        "\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "\n",
        "    # FLATTERN => DENSE => RELU => DROPOUT\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(512))\n",
        "\n",
        "    model.add(Activation({{choice(['relu', 'tanh'])}}))\n",
        "\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "\n",
        "    # a softmax classifier\n",
        "\n",
        "    model.add(Dense(num_classes))\n",
        "\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # initiate RMSprop optimizer\n",
        "    opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "\n",
        "\n",
        "    # Let's train the model using RMSprop\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}},\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    callback = EarlyStopping(monitor='loss', patience=5)\n",
        "    \n",
        "    result = None  # For recording the history of training process.\n",
        "\n",
        "    result = model.fit(X_train2, y_train2,\n",
        "                batch_size={{choice([16, 32, 64])}},\n",
        "                epochs={{choice([20,50,100])}},\n",
        "                verbose=2,\n",
        "                validation_split=0.1,\n",
        "                callbacks = [callback])\n",
        "    \n",
        "    # Score trained model.\n",
        "    scores = model.evaluate(X_val, y_val, verbose=1)\n",
        "\n",
        "    # make prediction.\n",
        "    pred = model.predict(x_test)\n",
        "\n",
        "    validation_acc = np.amax(result.history['val_accuracy']) \n",
        "    print('Best validation acc of epoch:', validation_acc)\n",
        "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
        "   "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en0PND9TsCB-"
      },
      "source": [
        "# See: https://stackoverflow.com/questions/49920031/get-the-path-of-the-notebook-on-google-colab\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Copy/download the file\n",
        "fid = drive.ListFile({'q':\"title='cifar10_cnn_tuning_hyporas_v2.ipynb'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('cifar10_cnn_tuning_hyporas_v2.ipynb')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzeMXh1uBz3L",
        "outputId": "8317e1da-ba3b-4dfb-9cf0-1f116ed12368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "best_run, best_model = optim.minimize(model=create_model,\n",
        "                                      data=data,\n",
        "                                      algo=tpe.suggest,\n",
        "                                      max_evals=5,\n",
        "                                      trials=Trials(),\n",
        "                                      notebook_name='cifar10_cnn_tuning_hyporas_v2')\n",
        "\n",
        "X_train2, y_train2, X_val, y_val = data()\n",
        "print(\"Evalutation of best performing model:\")\n",
        "print(best_model.evaluate(X_val, y_val)) \n",
        "print(\"Best performing model chosen hyper-parameters:\")\n",
        "print(best_run)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "try:\n",
            "    import os\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import seaborn as sns\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import matplotlib\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import matplotlib.pyplot as plt\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.metrics import confusion_matrix, classification_report\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import itertools\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import keras\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.datasets import cifar10\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.preprocessing.image import ImageDataGenerator\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Dense, Dropout, Activation, Flatten\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Conv2D, MaxPooling2D\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.callbacks import EarlyStopping\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import findspark\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import drive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.model_selection import train_test_split\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.auth import GoogleAuth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.drive import GoogleDrive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import auth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from oauth2client.client import GoogleCredentials\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'Conv2D': hp.choice('Conv2D', [16, 32, 64]),\n",
            "        'kernel_size': hp.choice('kernel_size', [(3, 3),(5,5)]),\n",
            "        'Conv2D_1': hp.choice('Conv2D_1', [16, 32, 64]),\n",
            "        'kernel_size_1': hp.choice('kernel_size_1', [(3, 3),(5,5)]),\n",
            "        'pool_size': hp.choice('pool_size', [(2, 2),(4,4)]),\n",
            "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
            "        'Conv2D_2': hp.choice('Conv2D_2', [16, 32, 64]),\n",
            "        'kernel_size_2': hp.choice('kernel_size_2', [(3, 3),(5,5)]),\n",
            "        'Conv2D_3': hp.choice('Conv2D_3', [16, 32, 64]),\n",
            "        'kernel_size_3': hp.choice('kernel_size_3', [(3, 3),(5,5)]),\n",
            "        'pool_size_1': hp.choice('pool_size_1', [(2, 2),(4,4)]),\n",
            "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
            "        'Activation': hp.choice('Activation', ['relu', 'tanh']),\n",
            "        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n",
            "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
            "        'Conv2D_4': hp.choice('Conv2D_4', [16, 32, 64]),\n",
            "        'epochs': hp.choice('epochs', [20,50,100]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "  1: \n",
            "  2: (X_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
            "  3: # X_train = X_train.reshape(50000, 3072)\n",
            "  4: # x_test = x_test.reshape(10000, 3072)\n",
            "  5: # Normalize the data. Before we need to connvert data type to float for computation.\n",
            "  6: X_train = X_train.astype('float32')\n",
            "  7: x_test = x_test.astype('float32')\n",
            "  8: X_train /= 255\n",
            "  9: x_test /= 255\n",
            " 10: num_classes = 10\n",
            " 11: \n",
            " 12: # Convert class vectors to binary class matrices. This is called one hot encoding.\n",
            " 13: y_train = keras.utils.to_categorical(y_train, num_classes)\n",
            " 14: y_test = keras.utils.to_categorical(y_test, num_classes)\n",
            " 15: X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, random_state=42, test_size=0.2)\n",
            " 16: \n",
            " 17: \n",
            " 18: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3: \n",
            "   4:     num_classes = 10\n",
            "   5: \n",
            "   6:     #define the convnet\n",
            "   7: \n",
            "   8:     model = Sequential()\n",
            "   9: \n",
            "  10:     # CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
            "  11: \n",
            "  12:     model.add(Conv2D(space['Conv2D'], \n",
            "  13:                      kernel_size=space['kernel_size'],\n",
            "  14:                      padding=\"valid\",input_shape=X_train2.shape[1:]))\n",
            "  15:     \n",
            "  16:     model.add(Activation('relu'))\n",
            "  17: \n",
            "  18:     model.add(Conv2D(space['Conv2D_1'], \n",
            "  19:                      kernel_size=space['kernel_size_1'],\n",
            "  20:                      padding=\"valid\"))\n",
            "  21:     \n",
            "  22:     model.add(Activation('relu'))\n",
            "  23: \n",
            "  24:     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
            "  25:     # model.add(MaxPooling2D(pool_size=space['pool_size']))\n",
            "  26: \n",
            "  27:     model.add(Dropout(space['Dropout']))\n",
            "  28: \n",
            "  29:     # CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
            "  30: \n",
            "  31:     model.add(Conv2D(space['Conv2D_2'], \n",
            "  32:                      kernel_size=space['kernel_size_2'], \n",
            "  33:                      padding='valid'))\n",
            "  34:     \n",
            "  35:     model.add(Activation('relu'))\n",
            "  36: \n",
            "  37:     model.add(Conv2D(space['Conv2D_3'], \n",
            "  38:                      kernel_size=space['kernel_size_3']))\n",
            "  39:     \n",
            "  40:     model.add(Activation('relu'))\n",
            "  41: \n",
            "  42:     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
            "  43:     # model.add(MaxPooling2D(pool_size=space['pool_size_1']))\n",
            "  44: \n",
            "  45:     model.add(Dropout(space['Dropout_1']))\n",
            "  46: \n",
            "  47:     # FLATTERN => DENSE => RELU => DROPOUT\n",
            "  48: \n",
            "  49:     model.add(Flatten())\n",
            "  50: \n",
            "  51:     model.add(Dense(512))\n",
            "  52: \n",
            "  53:     model.add(Activation(space['Activation']))\n",
            "  54: \n",
            "  55:     model.add(Dropout(space['Dropout_2']))\n",
            "  56: \n",
            "  57:     # a softmax classifier\n",
            "  58: \n",
            "  59:     model.add(Dense(num_classes))\n",
            "  60: \n",
            "  61:     model.add(Activation('softmax'))\n",
            "  62: \n",
            "  63:     # initiate RMSprop optimizer\n",
            "  64:     opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
            "  65: \n",
            "  66: \n",
            "  67: \n",
            "  68:     # Let's train the model using RMSprop\n",
            "  69:     model.compile(loss='categorical_crossentropy',\n",
            "  70:                   optimizer=space['optimizer'],\n",
            "  71:                   metrics=['accuracy'])\n",
            "  72:     \n",
            "  73:     callback = EarlyStopping(monitor='loss', patience=5)\n",
            "  74:     \n",
            "  75:     history = None  # For recording the history of training process.\n",
            "  76: \n",
            "  77:     history = model.fit(X_train2, y_train2,\n",
            "  78:                 batch_size=space['Conv2D_4'],\n",
            "  79:                 epochs=space['epochs'],\n",
            "  80:                 verbose=2,\n",
            "  81:                 validation_split=0.1,\n",
            "  82:                 callbacks = [callback])\n",
            "  83:     \n",
            "  84:     # Score trained model.\n",
            "  85:     scores = model.evaluate(X_val, y_val, verbose=1)\n",
            "  86: \n",
            "  87:     # make prediction.\n",
            "  88:     pred = model.predict(x_test)\n",
            "  89: \n",
            "  90:     validation_acc = np.amax(result.history['val_accuracy']) \n",
            "  91:     print('Best validation acc of epoch:', validation_acc)\n",
            "  92:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
            "  93: \n",
            "Epoch 1/50\n",
            "2250/2250 - 228s - loss: 1.9374 - accuracy: 0.2755 - val_loss: 1.7162 - val_accuracy: 0.3790\n",
            "\n",
            "Epoch 2/50\n",
            "2250/2250 - 230s - loss: 1.6903 - accuracy: 0.3957 - val_loss: 1.7034 - val_accuracy: 0.4030\n",
            "\n",
            "Epoch 3/50\n",
            "2250/2250 - 233s - loss: 1.6655 - accuracy: 0.4140 - val_loss: 1.5824 - val_accuracy: 0.4493\n",
            "\n",
            "Epoch 4/50\n",
            "2250/2250 - 229s - loss: 1.7296 - accuracy: 0.4001 - val_loss: 1.9111 - val_accuracy: 0.3760\n",
            "\n",
            "Epoch 5/50\n",
            "2250/2250 - 236s - loss: 1.8034 - accuracy: 0.3718 - val_loss: 1.7771 - val_accuracy: 0.3512\n",
            "\n",
            "Epoch 6/50\n",
            "2250/2250 - 233s - loss: 1.9447 - accuracy: 0.3336 - val_loss: 1.9215 - val_accuracy: 0.3713\n",
            "\n",
            "Epoch 7/50\n",
            "2250/2250 - 234s - loss: 1.9982 - accuracy: 0.3085 - val_loss: 2.0105 - val_accuracy: 0.3293\n",
            "\n",
            "Epoch 8/50\n",
            "2250/2250 - 234s - loss: 2.0640 - accuracy: 0.2801 - val_loss: 2.0899 - val_accuracy: 0.2643\n",
            "\n",
            "  1/313 [..............................]\n",
            " - ETA: 0s - loss: 2.0104 - accuracy: 0.2500\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "  2/313 [..............................]\n",
            " - ETA: 10s - loss: 2.0080 - accuracy: 0.3125\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "  3/313 [..............................]\n",
            " - ETA: 15s - loss: 1.9160 - accuracy: 0.3021\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "  4/313 [..............................]\n",
            " - ETA: 17s - loss: 1.9323 - accuracy: 0.2656\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "  5/313 [..............................]\n",
            " - ETA: 19s - loss: 1.9975 - accuracy: 0.2562\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "  6/313 [..............................]\n",
            " - ETA: 20s - loss: 1.9632 - accuracy: 0.2708\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "  7/313 [..............................]\n",
            " - ETA: 21s - loss: 1.9321 - accuracy: 0.2946\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "  8/313 [..............................]\n",
            " - ETA: 21s - loss: 1.9261 - accuracy: 0.2852\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "  9/313 [..............................]\n",
            " - ETA: 22s - loss: 1.9391 - accuracy: 0.2882\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 10/313 [..............................]\n",
            " - ETA: 22s - loss: 2.0389 - accuracy: 0.2719\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 11/313 [>.............................]\n",
            " - ETA: 22s - loss: 2.0396 - accuracy: 0.2756\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 12/313 [>.............................]\n",
            " - ETA: 22s - loss: 2.0789 - accuracy: 0.2708\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 13/313 [>.............................]\n",
            " - ETA: 23s - loss: 2.0966 - accuracy: 0.2692\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 14/313 [>.............................]\n",
            " - ETA: 23s - loss: 2.1323 - accuracy: 0.2522\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 15/313 [>.............................]\n",
            " - ETA: 23s - loss: 2.1030 - accuracy: 0.2625\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 16/313 [>.............................]\n",
            " - ETA: 23s - loss: 2.0881 - accuracy: 0.2617\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 17/313 [>.............................]\n",
            " - ETA: 23s - loss: 2.0874 - accuracy: 0.2647\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 18/313 [>.............................]\n",
            " - ETA: 23s - loss: 2.0767 - accuracy: 0.2622\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 19/313 [>.............................]\n",
            " - ETA: 23s - loss: 2.0936 - accuracy: 0.2599\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 20/313 [>.............................]\n",
            " - ETA: 23s - loss: 2.0873 - accuracy: 0.2594\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 21/313 [=>............................]\n",
            " - ETA: 23s - loss: 2.0745 - accuracy: 0.2589\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 22/313 [=>............................]\n",
            " - ETA: 23s - loss: 2.0633 - accuracy: 0.2599\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 23/313 [=>............................]\n",
            " - ETA: 23s - loss: 2.0693 - accuracy: 0.2568\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 24/313 [=>............................]\n",
            " - ETA: 23s - loss: 2.0594 - accuracy: 0.2591\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 25/313 [=>............................]\n",
            " - ETA: 23s - loss: 2.0572 - accuracy: 0.2587\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 26/313 [=>............................]\n",
            " - ETA: 23s - loss: 2.0469 - accuracy: 0.2608\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 27/313 [=>............................]\n",
            " - ETA: 23s - loss: 2.0461 - accuracy: 0.2604\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 28/313 [=>............................]\n",
            " - ETA: 23s - loss: 2.0513 - accuracy: 0.2556\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 29/313 [=>............................]\n",
            " - ETA: 23s - loss: 2.0539 - accuracy: 0.2565\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 30/313 [=>............................]\n",
            " - ETA: 23s - loss: 2.0514 - accuracy: 0.2573\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 31/313 [=>............................]\n",
            " - ETA: 23s - loss: 2.0505 - accuracy: 0.2571\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 32/313 [==>...........................]\n",
            " - ETA: 23s - loss: 2.0459 - accuracy: 0.2549\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 33/313 [==>...........................]\n",
            " - ETA: 23s - loss: 2.0444 - accuracy: 0.2538\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 34/313 [==>...........................]\n",
            " - ETA: 23s - loss: 2.0449 - accuracy: 0.2518\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 35/313 [==>...........................]\n",
            " - ETA: 23s - loss: 2.0480 - accuracy: 0.2527\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 36/313 [==>...........................]\n",
            " - ETA: 23s - loss: 2.0511 - accuracy: 0.2535\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 37/313 [==>...........................]\n",
            " - ETA: 23s - loss: 2.0463 - accuracy: 0.2525\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 38/313 [==>...........................]\n",
            " - ETA: 23s - loss: 2.0416 - accuracy: 0.2549\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 39/313 [==>...........................]\n",
            " - ETA: 23s - loss: 2.0464 - accuracy: 0.2540\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 40/313 [==>...........................]\n",
            " - ETA: 23s - loss: 2.0470 - accuracy: 0.2531\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 41/313 [==>...........................]\n",
            " - ETA: 23s - loss: 2.0447 - accuracy: 0.2530\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 42/313 [===>..........................]\n",
            " - ETA: 22s - loss: 2.0491 - accuracy: 0.2537\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 43/313 [===>..........................]\n",
            " - ETA: 23s - loss: 2.0465 - accuracy: 0.2529\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 44/313 [===>..........................]\n",
            " - ETA: 22s - loss: 2.0423 - accuracy: 0.2543\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 45/313 [===>..........................]\n",
            " - ETA: 22s - loss: 2.0514 - accuracy: 0.2556\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 46/313 [===>..........................]\n",
            " - ETA: 22s - loss: 2.0524 - accuracy: 0.2554\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 47/313 [===>..........................]\n",
            " - ETA: 22s - loss: 2.0558 - accuracy: 0.2533\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 48/313 [===>..........................]\n",
            " - ETA: 22s - loss: 2.0563 - accuracy: 0.2520\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 49/313 [===>..........................]\n",
            " - ETA: 22s - loss: 2.0508 - accuracy: 0.2532\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 50/313 [===>..........................]\n",
            " - ETA: 22s - loss: 2.0486 - accuracy: 0.2556\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 51/313 [===>..........................]\n",
            " - ETA: 22s - loss: 2.0443 - accuracy: 0.2567\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 52/313 [===>..........................]\n",
            " - ETA: 22s - loss: 2.0473 - accuracy: 0.2566\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 53/313 [====>.........................]\n",
            " - ETA: 22s - loss: 2.0502 - accuracy: 0.2577\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 54/313 [====>.........................]\n",
            " - ETA: 22s - loss: 2.0516 - accuracy: 0.2587\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 55/313 [====>.........................]\n",
            " - ETA: 22s - loss: 2.0525 - accuracy: 0.2602\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 56/313 [====>.........................]\n",
            " - ETA: 22s - loss: 2.0495 - accuracy: 0.2628\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 57/313 [====>.........................]\n",
            " - ETA: 22s - loss: 2.0585 - accuracy: 0.2632\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 58/313 [====>.........................]\n",
            " - ETA: 22s - loss: 2.0587 - accuracy: 0.2602\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 59/313 [====>.........................]\n",
            " - ETA: 22s - loss: 2.0635 - accuracy: 0.2595\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 60/313 [====>.........................]\n",
            " - ETA: 21s - loss: 2.0611 - accuracy: 0.2604\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 61/313 [====>.........................]\n",
            " - ETA: 21s - loss: 2.0626 - accuracy: 0.2602\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 62/313 [====>.........................]\n",
            " - ETA: 21s - loss: 2.0630 - accuracy: 0.2606\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 63/313 [=====>........................]\n",
            " - ETA: 21s - loss: 2.0648 - accuracy: 0.2604\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 64/313 [=====>........................]\n",
            " - ETA: 21s - loss: 2.0685 - accuracy: 0.2593\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 65/313 [=====>........................]\n",
            " - ETA: 21s - loss: 2.0669 - accuracy: 0.2611\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 66/313 [=====>........................]\n",
            " - ETA: 21s - loss: 2.0633 - accuracy: 0.2609\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 67/313 [=====>........................]\n",
            " - ETA: 21s - loss: 2.0617 - accuracy: 0.2607\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 68/313 [=====>........................]\n",
            " - ETA: 21s - loss: 2.0559 - accuracy: 0.2624\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 69/313 [=====>........................]\n",
            " - ETA: 21s - loss: 2.0551 - accuracy: 0.2618\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 70/313 [=====>........................]\n",
            " - ETA: 21s - loss: 2.0584 - accuracy: 0.2625\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 71/313 [=====>........................]\n",
            " - ETA: 21s - loss: 2.0581 - accuracy: 0.2619\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 72/313 [=====>........................]\n",
            " - ETA: 21s - loss: 2.0569 - accuracy: 0.2626\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 73/313 [=====>........................]\n",
            " - ETA: 21s - loss: 2.0572 - accuracy: 0.2620\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 74/313 [======>.......................]\n",
            " - ETA: 21s - loss: 2.0568 - accuracy: 0.2606\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 75/313 [======>.......................]\n",
            " - ETA: 21s - loss: 2.0537 - accuracy: 0.2608\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 76/313 [======>.......................]\n",
            " - ETA: 20s - loss: 2.0527 - accuracy: 0.2619\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 77/313 [======>.......................]\n",
            " - ETA: 20s - loss: 2.0578 - accuracy: 0.2610\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 78/313 [======>.......................]\n",
            " - ETA: 20s - loss: 2.0608 - accuracy: 0.2600\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 79/313 [======>.......................]\n",
            " - ETA: 20s - loss: 2.0592 - accuracy: 0.2603\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 80/313 [======>.......................]\n",
            " - ETA: 20s - loss: 2.0599 - accuracy: 0.2586\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 81/313 [======>.......................]\n",
            " - ETA: 20s - loss: 2.0575 - accuracy: 0.2581\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 82/313 [======>.......................]\n",
            " - ETA: 20s - loss: 2.0539 - accuracy: 0.2580\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 83/313 [======>.......................]\n",
            " - ETA: 20s - loss: 2.0550 - accuracy: 0.2568\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 84/313 [=======>......................]\n",
            " - ETA: 20s - loss: 2.0608 - accuracy: 0.2571\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 85/313 [=======>......................]\n",
            " - ETA: 20s - loss: 2.0596 - accuracy: 0.2577\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 86/313 [=======>......................]\n",
            " - ETA: 20s - loss: 2.0583 - accuracy: 0.2573\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 87/313 [=======>......................]\n",
            " - ETA: 20s - loss: 2.0552 - accuracy: 0.2586\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 88/313 [=======>......................]\n",
            " - ETA: 20s - loss: 2.0522 - accuracy: 0.2589\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 89/313 [=======>......................]\n",
            " - ETA: 20s - loss: 2.0487 - accuracy: 0.2591\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 90/313 [=======>......................]\n",
            " - ETA: 19s - loss: 2.0472 - accuracy: 0.2604\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 91/313 [=======>......................]\n",
            " - ETA: 19s - loss: 2.0492 - accuracy: 0.2593\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 92/313 [=======>......................]\n",
            " - ETA: 19s - loss: 2.0497 - accuracy: 0.2582\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 93/313 [=======>......................]\n",
            " - ETA: 19s - loss: 2.0508 - accuracy: 0.2587\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 94/313 [========>.....................]\n",
            " - ETA: 19s - loss: 2.0594 - accuracy: 0.2593\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 95/313 [========>.....................]\n",
            " - ETA: 19s - loss: 2.0586 - accuracy: 0.2595\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 96/313 [========>.....................]\n",
            " - ETA: 19s - loss: 2.0566 - accuracy: 0.2607\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 97/313 [========>.....................]\n",
            " - ETA: 19s - loss: 2.0543 - accuracy: 0.2610\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 98/313 [========>.....................]\n",
            " - ETA: 19s - loss: 2.0532 - accuracy: 0.2608\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 99/313 [========>.....................]\n",
            " - ETA: 19s - loss: 2.0571 - accuracy: 0.2607\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "100/313 [========>.....................]\n",
            " - ETA: 19s - loss: 2.0654 - accuracy: 0.2597\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "101/313 [========>.....................]\n",
            " - ETA: 19s - loss: 2.0674 - accuracy: 0.2584\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "102/313 [========>.....................]\n",
            " - ETA: 19s - loss: 2.0662 - accuracy: 0.2580\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "103/313 [========>.....................]\n",
            " - ETA: 19s - loss: 2.0666 - accuracy: 0.2576\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "104/313 [========>.....................]\n",
            " - ETA: 18s - loss: 2.0655 - accuracy: 0.2578\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "105/313 [=========>....................]\n",
            " - ETA: 18s - loss: 2.0682 - accuracy: 0.2577\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "106/313 [=========>....................]\n",
            " - ETA: 18s - loss: 2.0698 - accuracy: 0.2562\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "107/313 [=========>....................]\n",
            " - ETA: 18s - loss: 2.0677 - accuracy: 0.2564\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "108/313 [=========>....................]\n",
            " - ETA: 18s - loss: 2.0661 - accuracy: 0.2567\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "109/313 [=========>....................]\n",
            " - ETA: 18s - loss: 2.0656 - accuracy: 0.2563\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "110/313 [=========>....................]\n",
            " - ETA: 18s - loss: 2.0687 - accuracy: 0.2551\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "111/313 [=========>....................]\n",
            " - ETA: 18s - loss: 2.0711 - accuracy: 0.2551\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "112/313 [=========>....................]\n",
            " - ETA: 18s - loss: 2.0703 - accuracy: 0.2550\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "113/313 [=========>....................]\n",
            " - ETA: 18s - loss: 2.0705 - accuracy: 0.2553\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "114/313 [=========>....................]\n",
            " - ETA: 18s - loss: 2.0684 - accuracy: 0.2555\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "115/313 [==========>...................]\n",
            " - ETA: 18s - loss: 2.0690 - accuracy: 0.2554\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "116/313 [==========>...................]\n",
            " - ETA: 18s - loss: 2.0690 - accuracy: 0.2551\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "117/313 [==========>...................]\n",
            " - ETA: 18s - loss: 2.0699 - accuracy: 0.2540\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "118/313 [==========>...................]\n",
            " - ETA: 17s - loss: 2.0679 - accuracy: 0.2540\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "119/313 [==========>...................]\n",
            " - ETA: 17s - loss: 2.0668 - accuracy: 0.2539\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "120/313 [==========>...................]\n",
            " - ETA: 17s - loss: 2.0665 - accuracy: 0.2542\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "121/313 [==========>...................]\n",
            " - ETA: 17s - loss: 2.0647 - accuracy: 0.2541\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "122/313 [==========>...................]\n",
            " - ETA: 17s - loss: 2.0672 - accuracy: 0.2531\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "123/313 [==========>...................]\n",
            " - ETA: 17s - loss: 2.0677 - accuracy: 0.2538\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "124/313 [==========>...................]\n",
            " - ETA: 17s - loss: 2.0674 - accuracy: 0.2535\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "125/313 [==========>...................]\n",
            " - ETA: 17s - loss: 2.0668 - accuracy: 0.2542\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "126/313 [===========>..................]\n",
            " - ETA: 17s - loss: 2.0647 - accuracy: 0.2545\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "127/313 [===========>..................]\n",
            " - ETA: 17s - loss: 2.0646 - accuracy: 0.2537\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "128/313 [===========>..................]\n",
            " - ETA: 17s - loss: 2.0680 - accuracy: 0.2537\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "129/313 [===========>..................]\n",
            " - ETA: 17s - loss: 2.0669 - accuracy: 0.2529\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "130/313 [===========>..................]\n",
            " - ETA: 17s - loss: 2.0658 - accuracy: 0.2534\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "131/313 [===========>..................]\n",
            " - ETA: 17s - loss: 2.0641 - accuracy: 0.2543\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "132/313 [===========>..................]\n",
            " - ETA: 16s - loss: 2.0620 - accuracy: 0.2550\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "133/313 [===========>..................]\n",
            " - ETA: 16s - loss: 2.0735 - accuracy: 0.2549\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "134/313 [===========>..................]\n",
            " - ETA: 16s - loss: 2.0754 - accuracy: 0.2540\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "135/313 [===========>..................]\n",
            " - ETA: 16s - loss: 2.0730 - accuracy: 0.2539\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "136/313 [============>.................]\n",
            " - ETA: 16s - loss: 2.0728 - accuracy: 0.2539\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "137/313 [============>.................]\n",
            " - ETA: 16s - loss: 2.0743 - accuracy: 0.2539\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "138/313 [============>.................]\n",
            " - ETA: 16s - loss: 2.0747 - accuracy: 0.2534\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "139/313 [============>.................]\n",
            " - ETA: 16s - loss: 2.0767 - accuracy: 0.2531\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "140/313 [============>.................]\n",
            " - ETA: 16s - loss: 2.0765 - accuracy: 0.2536\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "141/313 [============>.................]\n",
            " - ETA: 16s - loss: 2.0788 - accuracy: 0.2535\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "142/313 [============>.................]\n",
            " - ETA: 16s - loss: 2.0792 - accuracy: 0.2535\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "143/313 [============>.................]\n",
            " - ETA: 16s - loss: 2.0814 - accuracy: 0.2539\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "144/313 [============>.................]\n",
            " - ETA: 15s - loss: 2.0813 - accuracy: 0.2530\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "145/313 [============>.................]\n",
            " - ETA: 15s - loss: 2.0797 - accuracy: 0.2541\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "146/313 [============>.................]\n",
            " - ETA: 15s - loss: 2.0772 - accuracy: 0.2551\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "147/313 [=============>................]\n",
            " - ETA: 15s - loss: 2.0775 - accuracy: 0.2545\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "148/313 [=============>................]\n",
            " - ETA: 15s - loss: 2.0779 - accuracy: 0.2546\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "149/313 [=============>................]\n",
            " - ETA: 15s - loss: 2.0791 - accuracy: 0.2544\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "150/313 [=============>................]\n",
            " - ETA: 15s - loss: 2.0840 - accuracy: 0.2546\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "151/313 [=============>................]\n",
            " - ETA: 15s - loss: 2.0827 - accuracy: 0.2546\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "152/313 [=============>................]\n",
            " - ETA: 15s - loss: 2.0817 - accuracy: 0.2539\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "153/313 [=============>................]\n",
            " - ETA: 15s - loss: 2.0820 - accuracy: 0.2535\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "154/313 [=============>................]\n",
            " - ETA: 15s - loss: 2.0813 - accuracy: 0.2534\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "155/313 [=============>................]\n",
            " - ETA: 15s - loss: 2.0924 - accuracy: 0.2534\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "156/313 [=============>................]\n",
            " - ETA: 14s - loss: 2.0910 - accuracy: 0.2542\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "157/313 [==============>...............]\n",
            " - ETA: 14s - loss: 2.0895 - accuracy: 0.2540\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "158/313 [==============>...............]\n",
            " - ETA: 14s - loss: 2.0884 - accuracy: 0.2536\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "159/313 [==============>...............]\n",
            " - ETA: 14s - loss: 2.0906 - accuracy: 0.2537\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "160/313 [==============>...............]\n",
            " - ETA: 14s - loss: 2.0892 - accuracy: 0.2543\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "161/313 [==============>...............]\n",
            " - ETA: 14s - loss: 2.0891 - accuracy: 0.2537\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "162/313 [==============>...............]\n",
            " - ETA: 14s - loss: 2.0881 - accuracy: 0.2541\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "163/313 [==============>...............]\n",
            " - ETA: 14s - loss: 2.0885 - accuracy: 0.2540\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "164/313 [==============>...............]\n",
            " - ETA: 14s - loss: 2.0889 - accuracy: 0.2538\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "165/313 [==============>...............]\n",
            " - ETA: 14s - loss: 2.0914 - accuracy: 0.2547\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "166/313 [==============>...............]\n",
            " - ETA: 14s - loss: 2.0902 - accuracy: 0.2549\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "167/313 [===============>..............]\n",
            " - ETA: 14s - loss: 2.0899 - accuracy: 0.2543\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "168/313 [===============>..............]\n",
            " - ETA: 13s - loss: 2.0897 - accuracy: 0.2537\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "169/313 [===============>..............]\n",
            " - ETA: 13s - loss: 2.0893 - accuracy: 0.2539\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "170/313 [===============>..............]\n",
            " - ETA: 13s - loss: 2.0885 - accuracy: 0.2546\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "171/313 [===============>..............]\n",
            " - ETA: 13s - loss: 2.0878 - accuracy: 0.2555\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "172/313 [===============>..............]\n",
            " - ETA: 13s - loss: 2.0866 - accuracy: 0.2553\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "173/313 [===============>..............]\n",
            " - ETA: 13s - loss: 2.0851 - accuracy: 0.2560\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "174/313 [===============>..............]\n",
            " - ETA: 13s - loss: 2.0837 - accuracy: 0.2565\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "175/313 [===============>..............]\n",
            " - ETA: 13s - loss: 2.0825 - accuracy: 0.2568\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "176/313 [===============>..............]\n",
            " - ETA: 13s - loss: 2.0831 - accuracy: 0.2566\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "177/313 [===============>..............]\n",
            " - ETA: 13s - loss: 2.0811 - accuracy: 0.2576\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "178/313 [================>.............]\n",
            " - ETA: 13s - loss: 2.0796 - accuracy: 0.2584\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "179/313 [================>.............]\n",
            " - ETA: 12s - loss: 2.0801 - accuracy: 0.2586\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "180/313 [================>.............]\n",
            " - ETA: 12s - loss: 2.0859 - accuracy: 0.2589\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "181/313 [================>.............]\n",
            " - ETA: 12s - loss: 2.0859 - accuracy: 0.2588\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "182/313 [================>.............]\n",
            " - ETA: 12s - loss: 2.0849 - accuracy: 0.2593\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "183/313 [================>.............]\n",
            " - ETA: 12s - loss: 2.0853 - accuracy: 0.2592\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "184/313 [================>.............]\n",
            " - ETA: 12s - loss: 2.0848 - accuracy: 0.2593\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "185/313 [================>.............]\n",
            " - ETA: 12s - loss: 2.0844 - accuracy: 0.2593\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "186/313 [================>.............]\n",
            " - ETA: 12s - loss: 2.0846 - accuracy: 0.2596\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "187/313 [================>.............]\n",
            " - ETA: 12s - loss: 2.0838 - accuracy: 0.2599\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "188/313 [=================>............]\n",
            " - ETA: 12s - loss: 2.0820 - accuracy: 0.2600\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "189/313 [=================>............]\n",
            " - ETA: 12s - loss: 2.0808 - accuracy: 0.2601\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "190/313 [=================>............]\n",
            " - ETA: 12s - loss: 2.0813 - accuracy: 0.2604\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "191/313 [=================>............]\n",
            " - ETA: 11s - loss: 2.0821 - accuracy: 0.2610\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "192/313 [=================>............]\n",
            " - ETA: 11s - loss: 2.0807 - accuracy: 0.2622\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "193/313 [=================>............]\n",
            " - ETA: 11s - loss: 2.0820 - accuracy: 0.2620\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "194/313 [=================>............]\n",
            " - ETA: 11s - loss: 2.0798 - accuracy: 0.2622\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "195/313 [=================>............]\n",
            " - ETA: 11s - loss: 2.0798 - accuracy: 0.2628\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "196/313 [=================>............]\n",
            " - ETA: 11s - loss: 2.0814 - accuracy: 0.2636\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "197/313 [=================>............]\n",
            " - ETA: 11s - loss: 2.0807 - accuracy: 0.2628\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "198/313 [=================>............]\n",
            " - ETA: 11s - loss: 2.0803 - accuracy: 0.2633\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "199/313 [==================>...........]\n",
            " - ETA: 11s - loss: 2.0792 - accuracy: 0.2633\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "200/313 [==================>...........]\n",
            " - ETA: 11s - loss: 2.0799 - accuracy: 0.2645\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "201/313 [==================>...........]\n",
            " - ETA: 11s - loss: 2.0802 - accuracy: 0.2640\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "202/313 [==================>...........]\n",
            " - ETA: 10s - loss: 2.0815 - accuracy: 0.2635\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "203/313 [==================>...........]\n",
            " - ETA: 10s - loss: 2.0813 - accuracy: 0.2637\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "204/313 [==================>...........]\n",
            " - ETA: 10s - loss: 2.0828 - accuracy: 0.2638\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "205/313 [==================>...........]\n",
            " - ETA: 10s - loss: 2.0841 - accuracy: 0.2639\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "206/313 [==================>...........]\n",
            " - ETA: 10s - loss: 2.0840 - accuracy: 0.2632\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "207/313 [==================>...........]\n",
            " - ETA: 10s - loss: 2.0857 - accuracy: 0.2627\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "208/313 [==================>...........]\n",
            " - ETA: 10s - loss: 2.0845 - accuracy: 0.2629\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "209/313 [===================>..........]\n",
            " - ETA: 10s - loss: 2.0841 - accuracy: 0.2630\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "210/313 [===================>..........]\n",
            " - ETA: 10s - loss: 2.0834 - accuracy: 0.2634\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "211/313 [===================>..........]\n",
            " - ETA: 10s - loss: 2.0859 - accuracy: 0.2635\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "212/313 [===================>..........]\n",
            " - ETA: 10s - loss: 2.0860 - accuracy: 0.2631\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "213/313 [===================>..........]\n",
            " - ETA: 9s - loss: 2.0850 - accuracy: 0.2634 \n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "214/313 [===================>..........]\n",
            " - ETA: 9s - loss: 2.0834 - accuracy: 0.2640\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "215/313 [===================>..........]\n",
            " - ETA: 9s - loss: 2.0842 - accuracy: 0.2642\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "216/313 [===================>..........]\n",
            " - ETA: 9s - loss: 2.0829 - accuracy: 0.2645\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "217/313 [===================>..........]\n",
            " - ETA: 9s - loss: 2.0832 - accuracy: 0.2644\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "218/313 [===================>..........]\n",
            " - ETA: 9s - loss: 2.0846 - accuracy: 0.2639\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "219/313 [===================>..........]\n",
            " - ETA: 9s - loss: 2.0851 - accuracy: 0.2640\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "220/313 [====================>.........]\n",
            " - ETA: 9s - loss: 2.0843 - accuracy: 0.2638\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "221/313 [====================>.........]\n",
            " - ETA: 9s - loss: 2.0841 - accuracy: 0.2634\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "222/313 [====================>.........]\n",
            " - ETA: 9s - loss: 2.0832 - accuracy: 0.2638\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "223/313 [====================>.........]\n",
            " - ETA: 9s - loss: 2.0840 - accuracy: 0.2639\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "224/313 [====================>.........]\n",
            " - ETA: 8s - loss: 2.0838 - accuracy: 0.2641\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "225/313 [====================>.........]\n",
            " - ETA: 8s - loss: 2.0830 - accuracy: 0.2643\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "226/313 [====================>.........]\n",
            " - ETA: 8s - loss: 2.0835 - accuracy: 0.2649\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "227/313 [====================>.........]\n",
            " - ETA: 8s - loss: 2.0839 - accuracy: 0.2651\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "228/313 [====================>.........]\n",
            " - ETA: 8s - loss: 2.0832 - accuracy: 0.2649\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "229/313 [====================>.........]\n",
            " - ETA: 8s - loss: 2.0826 - accuracy: 0.2646\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "230/313 [=====================>........]\n",
            " - ETA: 8s - loss: 2.0832 - accuracy: 0.2641\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "231/313 [=====================>........]\n",
            " - ETA: 8s - loss: 2.0829 - accuracy: 0.2639\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "232/313 [=====================>........]\n",
            " - ETA: 8s - loss: 2.0837 - accuracy: 0.2639\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "233/313 [=====================>........]\n",
            " - ETA: 8s - loss: 2.0851 - accuracy: 0.2638\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "234/313 [=====================>........]\n",
            " - ETA: 7s - loss: 2.0834 - accuracy: 0.2648\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "235/313 [=====================>........]\n",
            " - ETA: 7s - loss: 2.0828 - accuracy: 0.2649\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "236/313 [=====================>........]\n",
            " - ETA: 7s - loss: 2.0827 - accuracy: 0.2648\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "237/313 [=====================>........]\n",
            " - ETA: 7s - loss: 2.0825 - accuracy: 0.2649\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "238/313 [=====================>........]\n",
            " - ETA: 7s - loss: 2.0828 - accuracy: 0.2648\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "239/313 [=====================>........]\n",
            " - ETA: 7s - loss: 2.0834 - accuracy: 0.2646\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "240/313 [======================>.......]\n",
            " - ETA: 7s - loss: 2.0841 - accuracy: 0.2648\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "241/313 [======================>.......]\n",
            " - ETA: 7s - loss: 2.0845 - accuracy: 0.2645\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "242/313 [======================>.......]\n",
            " - ETA: 7s - loss: 2.0839 - accuracy: 0.2646\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "243/313 [======================>.......]\n",
            " - ETA: 7s - loss: 2.0838 - accuracy: 0.2649\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "244/313 [======================>.......]\n",
            " - ETA: 7s - loss: 2.0827 - accuracy: 0.2647\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "245/313 [======================>.......]\n",
            " - ETA: 6s - loss: 2.0820 - accuracy: 0.2653\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "246/313 [======================>.......]\n",
            " - ETA: 6s - loss: 2.0820 - accuracy: 0.2651\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "247/313 [======================>.......]\n",
            " - ETA: 6s - loss: 2.0820 - accuracy: 0.2652\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "248/313 [======================>.......]\n",
            " - ETA: 6s - loss: 2.0827 - accuracy: 0.2652\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "249/313 [======================>.......]\n",
            " - ETA: 6s - loss: 2.0830 - accuracy: 0.2648\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "250/313 [======================>.......]\n",
            " - ETA: 6s - loss: 2.0820 - accuracy: 0.2649\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "251/313 [=======================>......]\n",
            " - ETA: 6s - loss: 2.0805 - accuracy: 0.2654\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "252/313 [=======================>......]\n",
            " - ETA: 6s - loss: 2.0797 - accuracy: 0.2653\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "253/313 [=======================>......]\n",
            " - ETA: 6s - loss: 2.0789 - accuracy: 0.2653\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "254/313 [=======================>......]\n",
            " - ETA: 6s - loss: 2.0799 - accuracy: 0.2651\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "255/313 [=======================>......]\n",
            " - ETA: 5s - loss: 2.0797 - accuracy: 0.2653\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "256/313 [=======================>......]\n",
            " - ETA: 5s - loss: 2.0794 - accuracy: 0.2651\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "257/313 [=======================>......]\n",
            " - ETA: 5s - loss: 2.0801 - accuracy: 0.2651\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "258/313 [=======================>......]\n",
            " - ETA: 5s - loss: 2.0789 - accuracy: 0.2656\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "259/313 [=======================>......]\n",
            " - ETA: 5s - loss: 2.0794 - accuracy: 0.2653\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "260/313 [=======================>......]\n",
            " - ETA: 5s - loss: 2.0788 - accuracy: 0.2655\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "261/313 [========================>.....]\n",
            " - ETA: 5s - loss: 2.0774 - accuracy: 0.2657\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "262/313 [========================>.....]\n",
            " - ETA: 5s - loss: 2.0767 - accuracy: 0.2657\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "263/313 [========================>.....]\n",
            " - ETA: 5s - loss: 2.0753 - accuracy: 0.2659\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "264/313 [========================>.....]\n",
            " - ETA: 5s - loss: 2.0748 - accuracy: 0.2656\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "265/313 [========================>.....]\n",
            " - ETA: 4s - loss: 2.0738 - accuracy: 0.2660\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "266/313 [========================>.....]\n",
            " - ETA: 4s - loss: 2.0730 - accuracy: 0.2660\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "267/313 [========================>.....]\n",
            " - ETA: 4s - loss: 2.0723 - accuracy: 0.2664\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "268/313 [========================>.....]\n",
            " - ETA: 4s - loss: 2.0722 - accuracy: 0.2667\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "269/313 [========================>.....]\n",
            " - ETA: 4s - loss: 2.0722 - accuracy: 0.2667\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "270/313 [========================>.....]\n",
            " - ETA: 4s - loss: 2.0735 - accuracy: 0.2666\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "271/313 [========================>.....]\n",
            " - ETA: 4s - loss: 2.0729 - accuracy: 0.2661\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "272/313 [=========================>....]\n",
            " - ETA: 4s - loss: 2.0722 - accuracy: 0.2661\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "273/313 [=========================>....]\n",
            " - ETA: 4s - loss: 2.0718 - accuracy: 0.2664\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "274/313 [=========================>....]\n",
            " - ETA: 4s - loss: 2.0714 - accuracy: 0.2663\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "275/313 [=========================>....]\n",
            " - ETA: 3s - loss: 2.0721 - accuracy: 0.2661\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "276/313 [=========================>....]\n",
            " - ETA: 3s - loss: 2.0721 - accuracy: 0.2664\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "277/313 [=========================>....]\n",
            " - ETA: 3s - loss: 2.0736 - accuracy: 0.2662\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "278/313 [=========================>....]\n",
            " - ETA: 3s - loss: 2.0732 - accuracy: 0.2662\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "279/313 [=========================>....]\n",
            " - ETA: 3s - loss: 2.0728 - accuracy: 0.2659\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "280/313 [=========================>....]\n",
            " - ETA: 3s - loss: 2.0722 - accuracy: 0.2655\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "281/313 [=========================>....]\n",
            " - ETA: 3s - loss: 2.0718 - accuracy: 0.2651\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "282/313 [==========================>...]\n",
            " - ETA: 3s - loss: 2.0741 - accuracy: 0.2650\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "283/313 [==========================>...]\n",
            " - ETA: 3s - loss: 2.0734 - accuracy: 0.2656\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "284/313 [==========================>...]\n",
            " - ETA: 3s - loss: 2.0729 - accuracy: 0.2653\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "285/313 [==========================>...]\n",
            " - ETA: 2s - loss: 2.0722 - accuracy: 0.2650\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "286/313 [==========================>...]\n",
            " - ETA: 2s - loss: 2.0707 - accuracy: 0.2657\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "287/313 [==========================>...]\n",
            " - ETA: 2s - loss: 2.0699 - accuracy: 0.2663\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "288/313 [==========================>...]\n",
            " - ETA: 2s - loss: 2.0695 - accuracy: 0.2661\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "289/313 [==========================>...]\n",
            " - ETA: 2s - loss: 2.0699 - accuracy: 0.2659\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "290/313 [==========================>...]\n",
            " - ETA: 2s - loss: 2.0704 - accuracy: 0.2658\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "291/313 [==========================>...]\n",
            " - ETA: 2s - loss: 2.0702 - accuracy: 0.2659\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "292/313 [==========================>...]\n",
            " - ETA: 2s - loss: 2.0702 - accuracy: 0.2659\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "293/313 [===========================>..]\n",
            " - ETA: 2s - loss: 2.0692 - accuracy: 0.2660\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "294/313 [===========================>..]\n",
            " - ETA: 1s - loss: 2.0695 - accuracy: 0.2662\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "295/313 [===========================>..]\n",
            " - ETA: 1s - loss: 2.0689 - accuracy: 0.2666\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "296/313 [===========================>..]\n",
            " - ETA: 1s - loss: 2.0685 - accuracy: 0.2668\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "297/313 [===========================>..]\n",
            " - ETA: 1s - loss: 2.0734 - accuracy: 0.2666\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "298/313 [===========================>..]\n",
            " - ETA: 1s - loss: 2.0725 - accuracy: 0.2665\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "299/313 [===========================>..]\n",
            " - ETA: 1s - loss: 2.0725 - accuracy: 0.2664\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "300/313 [===========================>..]\n",
            " - ETA: 1s - loss: 2.0735 - accuracy: 0.2666\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "301/313 [===========================>..]\n",
            " - ETA: 1s - loss: 2.0744 - accuracy: 0.2662\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "302/313 [===========================>..]\n",
            " - ETA: 1s - loss: 2.0737 - accuracy: 0.2661\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "303/313 [============================>.]\n",
            " - ETA: 1s - loss: 2.0736 - accuracy: 0.2660\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "304/313 [============================>.]\n",
            " - ETA: 0s - loss: 2.0737 - accuracy: 0.2663\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "305/313 [============================>.]\n",
            " - ETA: 0s - loss: 2.0730 - accuracy: 0.2660\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "306/313 [============================>.]\n",
            " - ETA: 0s - loss: 2.0719 - accuracy: 0.2660\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "307/313 [============================>.]\n",
            " - ETA: 0s - loss: 2.0723 - accuracy: 0.2659\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "308/313 [============================>.]\n",
            " - ETA: 0s - loss: 2.0744 - accuracy: 0.2656\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "309/313 [============================>.]\n",
            " - ETA: 0s - loss: 2.0738 - accuracy: 0.2658\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "310/313 [============================>.]\n",
            " - ETA: 0s - loss: 2.0734 - accuracy: 0.2656\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "311/313 [============================>.]\n",
            " - ETA: 0s - loss: 2.0757 - accuracy: 0.2654\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "312/313 [============================>.]\n",
            " - ETA: 0s - loss: 2.0761 - accuracy: 0.2653\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "313/313 [==============================]\n",
            " - ETA: 0s - loss: 2.0764 - accuracy: 0.2654\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "313/313 [==============================]\n",
            " - 33s 106ms/step - loss: 2.0764 - accuracy: 0.2654\n",
            "\n",
            "  0%|          | 0/5 [31:46<?, ?it/s, best loss: ?]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1e7793b5121a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                       \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                       \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                       notebook_name='cifar10_cnn_tuning_hyporas_v2')\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                                      keep_temp=keep_temp)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[1;32m    137\u001b[0m              \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m              \u001b[0mrstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m              return_argmin=True),\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mget_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         )\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             show_progressbar=show_progressbar)\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    405\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    406\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/temp_model.py\u001b[0m in \u001b[0;36mkeras_fmin_fnct\u001b[0;34m(space)\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myIevp41of-G"
      },
      "source": [
        "def plotmodelhistory(history): \n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(history.history['accuracy']) \n",
        "    axs[0].plot(history.history['val_accuracy']) \n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy') \n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(history.history['loss']) \n",
        "    axs[1].plot(history.history['val_loss']) \n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss') \n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "plotmodelhistory(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOCXA4adohRd"
      },
      "source": [
        "# # Score trained model.\n",
        "# scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "\n",
        "# # make prediction.\n",
        "# pred = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjB5OEUWomNu"
      },
      "source": [
        "def heatmap(data, row_labels, col_labels, ax=None, cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
        "    \"\"\"\n",
        "    Create a heatmap from a numpy array and two lists of labels.\n",
        "    \"\"\"\n",
        "    if not ax:\n",
        "        ax = plt.gca()\n",
        "\n",
        "    # Plot the heatmap\n",
        "    im = ax.imshow(data, **kwargs)\n",
        "\n",
        "    # Create colorbar\n",
        "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
        "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
        "\n",
        "    # Let the horizontal axes labeling appear on top.\n",
        "    ax.tick_params(top=True, bottom=False,\n",
        "                   labeltop=True, labelbottom=False)\n",
        "    # We want to show all ticks...\n",
        "    ax.set_xticks(np.arange(data.shape[1]))\n",
        "    ax.set_yticks(np.arange(data.shape[0]))\n",
        "    # ... and label them with the respective list entries.\n",
        "    ax.set_xticklabels(col_labels)\n",
        "    ax.set_yticklabels(row_labels)\n",
        "    \n",
        "    ax.set_xlabel('Predicted Label') \n",
        "    ax.set_ylabel('True Label')\n",
        "    \n",
        "    return im, cbar\n",
        "\n",
        "def annotate_heatmap(im, data=None, fmt=\"d\", threshold=None):\n",
        "    \"\"\"\n",
        "    A function to annotate a heatmap.\n",
        "    \"\"\"\n",
        "    # Change the text's color depending on the data.\n",
        "    texts = []\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(data.shape[1]):\n",
        "            text = im.axes.text(j, i, format(data[i, j], fmt), horizontalalignment=\"center\",\n",
        "                                 color=\"white\" if data[i, j] > thresh else \"black\")\n",
        "            texts.append(text)\n",
        "\n",
        "    return texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np3wd-Zyonra"
      },
      "source": [
        "labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "\n",
        "# Convert predictions classes to one hot vectors \n",
        "Y_pred_classes = np.argmax(pred, axis=1) \n",
        "# Convert validation observations to one hot vectors\n",
        "Y_true = np.argmax(y_test, axis=1)\n",
        "# Errors are difference between predicted labels and true labels\n",
        "errors = (Y_pred_classes - Y_true != 0)\n",
        "\n",
        "Y_pred_classes_errors = Y_pred_classes[errors]\n",
        "Y_pred_errors = pred[errors]\n",
        "Y_true_errors = Y_true[errors]\n",
        "X_test_errors = x_test[errors]\n",
        "\n",
        "cm = confusion_matrix(Y_true, Y_pred_classes) \n",
        "thresh = cm.max() / 2.\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,12))\n",
        "im, cbar = heatmap(cm, labels, labels, ax=ax,\n",
        "                   cmap=plt.cm.Blues, cbarlabel=\"count of predictions\")\n",
        "texts = annotate_heatmap(im, data=cm, threshold=thresh)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTUfyE7wop5d"
      },
      "source": [
        "print(classification_report(Y_true, Y_pred_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eep1Wzk9or-e"
      },
      "source": [
        "R = 5\n",
        "C = 5\n",
        "fig, axes = plt.subplots(R, C, figsize=(12,12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in np.arange(0, R*C):\n",
        "    axes[i].imshow(x_test[i])\n",
        "    axes[i].set_title(\"True: %s \\nPredict: %s\" % (labels[Y_true[i]], labels[Y_pred_classes[i]]))\n",
        "    axes[i].axis('off')\n",
        "    plt.subplots_adjust(wspace=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foLl4umBot52"
      },
      "source": [
        "def display_errors(errors_index, img_errors, pred_errors, obs_errors):\n",
        "    \"\"\" This function shows 10 images with their predicted and real labels\"\"\"\n",
        "    n = 0\n",
        "    nrows = 2\n",
        "    ncols = 5\n",
        "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True, figsize=(12,6))\n",
        "    for row in range(nrows):\n",
        "        for col in range(ncols):\n",
        "            error = errors_index[n]\n",
        "            ax[row,col].imshow((img_errors[error]).reshape((32,32,3)))\n",
        "            ax[row,col].set_title(\"Predicted:{}\\nTrue:{}\".\n",
        "                                  format(labels[pred_errors[error]],labels[obs_errors[error]]))\n",
        "            n += 1\n",
        "            ax[row,col].axis('off')\n",
        "            plt.subplots_adjust(wspace=1)\n",
        "\n",
        "# Probabilities of the wrong predicted numbers\n",
        "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
        "\n",
        "# Predicted probabilities of the true values in the error set\n",
        "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
        "\n",
        "# Difference between the probability of the predicted label and the true label\n",
        "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
        "\n",
        "# Sorted list of the delta prob errors\n",
        "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
        "\n",
        "# Top 10 errors \n",
        "most_important_errors = sorted_dela_errors[-10:]\n",
        "\n",
        "# Show the top 10 errors\n",
        "display_errors(most_important_errors, X_test_errors, Y_pred_classes_errors, Y_true_errors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGcArwqIovlA"
      },
      "source": [
        "def show_test(number):\n",
        "    fig = plt.figure(figsize = (3,3))\n",
        "    test_image = np.expand_dims(x_test[number], axis=0)\n",
        "    test_result = model.predict_classes(test_image)\n",
        "    plt.imshow(x_test[number])\n",
        "    dict_key = test_result[0]\n",
        "    plt.title(\"Predicted: {} \\nTrue Label: {}\".format(labels[dict_key],\n",
        "                                                      labels[Y_true[number]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP71Y27UoxBG"
      },
      "source": [
        "show_test(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBhjagnmoyXs"
      },
      "source": [
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}