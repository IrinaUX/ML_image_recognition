{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10-cnn-tuning-hyporas.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxvKic7TrXF1",
        "outputId": "3a681ea7-f0d7-4003-933e-65fdeec56b85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 2.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-2.4.6'\n",
        "spark_version = 'spark-3.0.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install hyperas\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice,uniform\n",
        "\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [335 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,681 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,733 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [231 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,112 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,348 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,150 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [45.5 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [860 kB]\n",
            "Fetched 10.8 MB in 3s (3,224 kB/s)\n",
            "Reading package lists... Done\n",
            "Collecting hyperas\n",
            "  Downloading https://files.pythonhosted.org/packages/04/34/87ad6ffb42df9c1fa9c4c906f65813d42ad70d68c66af4ffff048c228cd4/hyperas-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.4.3)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.1.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.6.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.0.7)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.10.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (7.5.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.7.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.10.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (4.41.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (3.11.0)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.2.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (4.6.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (4.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.6.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (5.3.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (3.5.1)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (19.0.2)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (1.9.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (1.0.18)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.9.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (1.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt->hyperas) (4.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (20.4)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (50.3.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter->hyperas) (2.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->hyperas) (0.6.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->hyperas) (2.4.7)\n",
            "Installing collected packages: hyperas\n",
            "Successfully installed hyperas-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXP0TDbd4LpT"
      },
      "source": [
        "batch_size = 32  # The default batch size of keras.\n",
        "num_classes = 10  # Number of class for the dataset\n",
        "epochs = 50\n",
        "data_augmentation = False"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWvb-FuH2uBu",
        "outputId": "2abd5eef-c605-4175-d4fe-5ba70a11c147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM9OTlp05Neq",
        "outputId": "d53b9511-c7c8-43e8-cb8d-9454d4e08512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
        "# Count plot for training set\n",
        "sns.countplot(y_train.ravel(), ax=axs[0])\n",
        "axs[0].set_title('Distribution of training data')\n",
        "axs[0].set_xlabel('Classes')\n",
        "# Count plot for testing set\n",
        "sns.countplot(y_test.ravel(), ax=axs[1])\n",
        "axs[1].set_title('Distribution of Testing data')\n",
        "axs[1].set_xlabel('Classes')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tBiBCA25OrC"
      },
      "source": [
        "# Normalize the data. Before we need to connvert data type to float for computation.\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices. This is called one hot encoding.\n",
        "y_train_cat = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test_cat = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqq676_r-Td-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# X_train2, X_val, y_train2, y_val = train_test_split(x_train, y_train_cat, random_state=42, test_size=0.2)\n",
        "def data(x_train, y_train_cat):\n",
        "    X_train2, X_val, y_train2, y_val = train_test_split(x_train, y_train_cat, random_state=42, test_size=0.2)\n",
        "    return X_train2, y_train2, X_val, y_val"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-MGOuYy-qT2",
        "outputId": "ba190fce-c5d7-4a79-ef17-d972609e2dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "X_train2, y_train2, X_val, y_val = data(x_train, y_train_cat)\n",
        "print('x_train shape:', X_train2.shape)\n",
        "print('y_train shape:', y_train2.shape)\n",
        "print('x_val shape:', X_val.shape)\n",
        "print('y_val shape:', y_val.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (40000, 32, 32, 3)\n",
            "y_train shape: (40000, 10)\n",
            "x_val shape: (10000, 32, 32, 3)\n",
            "y_val shape: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS9Dgo8C5Rxj"
      },
      "source": [
        "def create_model(X_train2, y_train2, X_val, y_val):\n",
        "    #define the convnet\n",
        "\n",
        "    model = Sequential()\n",
        "    # CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "    model.add(Conv2D({{choice([32, 64, 128])}}, kernel_size={{choice([(3, 3),(5,5)])}},padding=\"same\",input_shape=X_train2.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D({{choice([32, 64, 128])}}, kernel_size={{choice([(3, 3),(5,5)])}},padding=\"same\"))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size={{choice([(2, 2),(4,4)])}}))\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "\n",
        "    # CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "    model.add(Conv2D({{choice([32, 64, 128])}}, kernel_size={{choice([(3, 3),(5,5)])}}, padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D({{choice([32, 64, 128])}}, kernel_size={{choice([(3, 3),(5,5)])}}))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size={{choice([(2, 2),(4,4)])}}))\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "\n",
        "    # FLATTERN => DENSE => RELU => DROPOUT\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation({{choice(['relu', 'tanh'])}}))\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "    # a softmax classifier\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # initiate RMSprop optimizer\n",
        "    opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "    # Let's train the model using RMSprop\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}},\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    history = None  # For recording the history of training process.\n",
        "    history = model.fit(x_train, y_train,\n",
        "                batch_size={{choice([32, 64, 128])}},\n",
        "                epochs={{choice([20,50,100])}},\n",
        "                verbose=2,\n",
        "                validation_data=(x_test, y_test))\n",
        "    \n",
        "    # Score trained model.\n",
        "    scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "    # make prediction.\n",
        "    pred = model.predict(x_test)\n",
        "\n",
        "    return pred, scores, history\n",
        "\n",
        "   "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en0PND9TsCB-"
      },
      "source": [
        "# See: https://stackoverflow.com/questions/49920031/get-the-path-of-the-notebook-on-google-colab\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Copy/download the file\n",
        "fid = drive.ListFile({'q':\"title='cifar10-cnn-tuning-hyporas.ipynb'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('cifar10-cnn-tuning-hyporas.ipynb')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzeMXh1uBz3L",
        "outputId": "79b82241-2ad0-41eb-829d-e69f5dd81a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "best_run, best_model = optim.minimize(model=create_model,\n",
        "                                      data=data,\n",
        "                                      algo=tpe.suggest,\n",
        "                                      max_evals=5,\n",
        "                                      trials=Trials(),\n",
        "                                      notebook_name=os.path.join('cifar10-cnn-tuning-hyporas'))\n",
        "\n",
        "X_train2, y_train2, X_val, y_val = data(x_train, y_train_cat)\n",
        "print(\"Evalutation of best performing model:\")\n",
        "print(best_model.evaluate(X_test, Y_test))\n",
        "print(\"Best performing model chosen hyper-parameters:\")\n",
        "print(best_run)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "try:\n",
            "    import os\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import seaborn as sns\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import matplotlib\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import matplotlib.pyplot as plt\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.metrics import confusion_matrix, classification_report\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import itertools\n",
            "except:\n",
            "    pass\n",
            "\n",
            "from __future__ import print_function\n",
            "\n",
            "try:\n",
            "    import keras\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.datasets import cifar10\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.preprocessing.image import ImageDataGenerator\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Dense, Dropout, Activation, Flatten\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Conv2D, MaxPooling2D\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import os\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import findspark\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.model_selection import train_test_split\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.auth import GoogleAuth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.drive import GoogleDrive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import auth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from oauth2client.client import GoogleCredentials\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'Conv2D': hp.choice('Conv2D', [32, 64, 128]),\n",
            "        'kernel_size': hp.choice('kernel_size', [(3, 3),(5,5)]),\n",
            "        'Conv2D_1': hp.choice('Conv2D_1', [32, 64, 128]),\n",
            "        'kernel_size_1': hp.choice('kernel_size_1', [(3, 3),(5,5)]),\n",
            "        'pool_size': hp.choice('pool_size', [(2, 2),(4,4)]),\n",
            "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
            "        'Conv2D_2': hp.choice('Conv2D_2', [32, 64, 128]),\n",
            "        'kernel_size_2': hp.choice('kernel_size_2', [(3, 3),(5,5)]),\n",
            "        'Conv2D_3': hp.choice('Conv2D_3', [32, 64, 128]),\n",
            "        'kernel_size_3': hp.choice('kernel_size_3', [(3, 3),(5,5)]),\n",
            "        'pool_size_1': hp.choice('pool_size_1', [(2, 2),(4,4)]),\n",
            "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
            "        'Activation': hp.choice('Activation', ['relu', 'tanh']),\n",
            "        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n",
            "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
            "        'Conv2D_4': hp.choice('Conv2D_4', [32, 64, 128]),\n",
            "        'epochs': hp.choice('epochs', [20,50,100]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "  1: \n",
            "  2: X_train2, X_val, y_train2, y_val = train_test_split(x_train, y_train_cat, random_state=42, test_size=0.2)\n",
            "  3: \n",
            "  4: \n",
            "  5: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3:     #define the convnet\n",
            "   4: \n",
            "   5:     model = Sequential()\n",
            "   6:     # CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
            "   7:     model.add(Conv2D(space['Conv2D'], kernel_size=space['kernel_size'],padding=\"same\",input_shape=X_train2.shape[1:]))\n",
            "   8:     model.add(Activation('relu'))\n",
            "   9:     model.add(Conv2D(space['Conv2D_1'], kernel_size=space['kernel_size_1'],padding=\"same\"))\n",
            "  10:     model.add(Activation('relu'))\n",
            "  11:     model.add(MaxPooling2D(pool_size=space['pool_size']))\n",
            "  12:     model.add(Dropout(space['Dropout']))\n",
            "  13: \n",
            "  14:     # CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
            "  15:     model.add(Conv2D(space['Conv2D_2'], kernel_size=space['kernel_size_2'], padding='same'))\n",
            "  16:     model.add(Activation('relu'))\n",
            "  17:     model.add(Conv2D(space['Conv2D_3'], kernel_size=space['kernel_size_3']))\n",
            "  18:     model.add(Activation('relu'))\n",
            "  19:     model.add(MaxPooling2D(pool_size=space['pool_size_1']))\n",
            "  20:     model.add(Dropout(space['Dropout_1']))\n",
            "  21: \n",
            "  22:     # FLATTERN => DENSE => RELU => DROPOUT\n",
            "  23:     model.add(Flatten())\n",
            "  24:     model.add(Dense(512))\n",
            "  25:     model.add(Activation(space['Activation']))\n",
            "  26:     model.add(Dropout(space['Dropout_2']))\n",
            "  27:     # a softmax classifier\n",
            "  28:     model.add(Dense(num_classes))\n",
            "  29:     model.add(Activation('softmax'))\n",
            "  30: \n",
            "  31:     # initiate RMSprop optimizer\n",
            "  32:     opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
            "  33: \n",
            "  34:     # Let's train the model using RMSprop\n",
            "  35:     model.compile(loss='categorical_crossentropy',\n",
            "  36:                   optimizer=space['optimizer'],\n",
            "  37:                   metrics=['accuracy'])\n",
            "  38:     \n",
            "  39:     history = None  # For recording the history of training process.\n",
            "  40:     history = model.fit(x_train, y_train,\n",
            "  41:                 batch_size=space['Conv2D_4'],\n",
            "  42:                 epochs=space['epochs'],\n",
            "  43:                 verbose=2,\n",
            "  44:                 validation_data=(x_test, y_test))\n",
            "  45:     \n",
            "  46:     # Score trained model.\n",
            "  47:     scores = model.evaluate(x_test, y_test, verbose=1)\n",
            "  48: \n",
            "  49:     # make prediction.\n",
            "  50:     pred = model.predict(x_test)\n",
            "  51: \n",
            "  52:     return pred, scores, history\n",
            "  53: \n",
            "Unexpected error: <class 'SyntaxError'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/content/temp_model.py\"\u001b[0;36m, line \u001b[0;32m33\u001b[0m\n\u001b[0;31m    from __future__ import print_function\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m from __future__ imports must occur at the beginning of the file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myIevp41of-G"
      },
      "source": [
        "def plotmodelhistory(history): \n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(history.history['accuracy']) \n",
        "    axs[0].plot(history.history['val_accuracy']) \n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy') \n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(history.history['loss']) \n",
        "    axs[1].plot(history.history['val_loss']) \n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss') \n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "plotmodelhistory(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOCXA4adohRd"
      },
      "source": [
        "# # Score trained model.\n",
        "# scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "\n",
        "# # make prediction.\n",
        "# pred = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjB5OEUWomNu"
      },
      "source": [
        "def heatmap(data, row_labels, col_labels, ax=None, cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
        "    \"\"\"\n",
        "    Create a heatmap from a numpy array and two lists of labels.\n",
        "    \"\"\"\n",
        "    if not ax:\n",
        "        ax = plt.gca()\n",
        "\n",
        "    # Plot the heatmap\n",
        "    im = ax.imshow(data, **kwargs)\n",
        "\n",
        "    # Create colorbar\n",
        "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
        "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
        "\n",
        "    # Let the horizontal axes labeling appear on top.\n",
        "    ax.tick_params(top=True, bottom=False,\n",
        "                   labeltop=True, labelbottom=False)\n",
        "    # We want to show all ticks...\n",
        "    ax.set_xticks(np.arange(data.shape[1]))\n",
        "    ax.set_yticks(np.arange(data.shape[0]))\n",
        "    # ... and label them with the respective list entries.\n",
        "    ax.set_xticklabels(col_labels)\n",
        "    ax.set_yticklabels(row_labels)\n",
        "    \n",
        "    ax.set_xlabel('Predicted Label') \n",
        "    ax.set_ylabel('True Label')\n",
        "    \n",
        "    return im, cbar\n",
        "\n",
        "def annotate_heatmap(im, data=None, fmt=\"d\", threshold=None):\n",
        "    \"\"\"\n",
        "    A function to annotate a heatmap.\n",
        "    \"\"\"\n",
        "    # Change the text's color depending on the data.\n",
        "    texts = []\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(data.shape[1]):\n",
        "            text = im.axes.text(j, i, format(data[i, j], fmt), horizontalalignment=\"center\",\n",
        "                                 color=\"white\" if data[i, j] > thresh else \"black\")\n",
        "            texts.append(text)\n",
        "\n",
        "    return texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np3wd-Zyonra"
      },
      "source": [
        "labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "\n",
        "# Convert predictions classes to one hot vectors \n",
        "Y_pred_classes = np.argmax(pred, axis=1) \n",
        "# Convert validation observations to one hot vectors\n",
        "Y_true = np.argmax(y_test, axis=1)\n",
        "# Errors are difference between predicted labels and true labels\n",
        "errors = (Y_pred_classes - Y_true != 0)\n",
        "\n",
        "Y_pred_classes_errors = Y_pred_classes[errors]\n",
        "Y_pred_errors = pred[errors]\n",
        "Y_true_errors = Y_true[errors]\n",
        "X_test_errors = x_test[errors]\n",
        "\n",
        "cm = confusion_matrix(Y_true, Y_pred_classes) \n",
        "thresh = cm.max() / 2.\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,12))\n",
        "im, cbar = heatmap(cm, labels, labels, ax=ax,\n",
        "                   cmap=plt.cm.Blues, cbarlabel=\"count of predictions\")\n",
        "texts = annotate_heatmap(im, data=cm, threshold=thresh)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTUfyE7wop5d"
      },
      "source": [
        "print(classification_report(Y_true, Y_pred_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eep1Wzk9or-e"
      },
      "source": [
        "R = 5\n",
        "C = 5\n",
        "fig, axes = plt.subplots(R, C, figsize=(12,12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in np.arange(0, R*C):\n",
        "    axes[i].imshow(x_test[i])\n",
        "    axes[i].set_title(\"True: %s \\nPredict: %s\" % (labels[Y_true[i]], labels[Y_pred_classes[i]]))\n",
        "    axes[i].axis('off')\n",
        "    plt.subplots_adjust(wspace=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foLl4umBot52"
      },
      "source": [
        "def display_errors(errors_index, img_errors, pred_errors, obs_errors):\n",
        "    \"\"\" This function shows 10 images with their predicted and real labels\"\"\"\n",
        "    n = 0\n",
        "    nrows = 2\n",
        "    ncols = 5\n",
        "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True, figsize=(12,6))\n",
        "    for row in range(nrows):\n",
        "        for col in range(ncols):\n",
        "            error = errors_index[n]\n",
        "            ax[row,col].imshow((img_errors[error]).reshape((32,32,3)))\n",
        "            ax[row,col].set_title(\"Predicted:{}\\nTrue:{}\".\n",
        "                                  format(labels[pred_errors[error]],labels[obs_errors[error]]))\n",
        "            n += 1\n",
        "            ax[row,col].axis('off')\n",
        "            plt.subplots_adjust(wspace=1)\n",
        "\n",
        "# Probabilities of the wrong predicted numbers\n",
        "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
        "\n",
        "# Predicted probabilities of the true values in the error set\n",
        "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
        "\n",
        "# Difference between the probability of the predicted label and the true label\n",
        "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
        "\n",
        "# Sorted list of the delta prob errors\n",
        "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
        "\n",
        "# Top 10 errors \n",
        "most_important_errors = sorted_dela_errors[-10:]\n",
        "\n",
        "# Show the top 10 errors\n",
        "display_errors(most_important_errors, X_test_errors, Y_pred_classes_errors, Y_true_errors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGcArwqIovlA"
      },
      "source": [
        "def show_test(number):\n",
        "    fig = plt.figure(figsize = (3,3))\n",
        "    test_image = np.expand_dims(x_test[number], axis=0)\n",
        "    test_result = model.predict_classes(test_image)\n",
        "    plt.imshow(x_test[number])\n",
        "    dict_key = test_result[0]\n",
        "    plt.title(\"Predicted: {} \\nTrue Label: {}\".format(labels[dict_key],\n",
        "                                                      labels[Y_true[number]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP71Y27UoxBG"
      },
      "source": [
        "show_test(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBhjagnmoyXs"
      },
      "source": [
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}